{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5364f082-392e-4e49-a60c-37b1f5877c0e",
   "metadata": {},
   "source": [
    "<h1>Generative Adversarial Network</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698c06c2-f46a-4dba-b1ec-a58cc85094dc",
   "metadata": {},
   "source": [
    "Usefuls links:\n",
    "<ul>\n",
    "    <li><a href='https://www.quora.com/What-are-some-recent-and-potentially-upcoming-breakthroughs-in-deep-learning' target='_blank'>https://www.quora.com/What-are-some-recent-and-potentially-upcoming-breakthroughs-in-deep-learning</a></li>\n",
    "    <li><a href='https://arxiv.org/abs/1701.00160' target='_blank'>NIPS 2016 Tutorial: Generative Adversarial Networks</a></li>\n",
    "    <li><a href='https://arxiv.org/abs/1612.03242' traget='_blank'>StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks</a></li>\n",
    "    <li><a href='https://arxiv.org/abs/1511.06434v1' target='_blank'>Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks</a></li>\n",
    "    <li><a href='https://github.com/soumith/ganhacks' target='_blank'>How to Train a GAN? Tips and tricks to make GANs work</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cf7d6b2-601a-4b53-ae19-dd037c82a07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theano\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mlxtend.data import loadlocal_mnist\n",
    "from PIL import Image\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.layers.core import Dense, Activation, Dropout, Flatten\n",
    "from keras.models import Sequential, load_model, save_model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D, UpSampling2D\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering(dim_ordering=\"th\") #we want to use Theano backend image dim order\n",
    "print(K.backend()) #we use Theano as backend\n",
    "#we can see that Theano is used in /media/anthony/USOPP/conda/IA/etc/conda/activate.d/keras_activate.sh\n",
    "\n",
    "import tensorboard\n",
    "%matplotlib inline\n",
    "np.random.seed(seed=777)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b3e24e-e7f1-40e2-9310-8e90298b78e1",
   "metadata": {},
   "source": [
    "<h2>A) Forging MNIST data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33c2fe44-5127-454d-8dc9-906d4881fd25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mUpSampling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Upsampling layer for 2D inputs.\n",
       "\n",
       "Repeats the rows and columns of the data\n",
       "by size[0] and size[1] respectively.\n",
       "\n",
       "# Arguments\n",
       "    size: int, or tuple of 2 integers.\n",
       "        The upsampling factors for rows and columns.\n",
       "    data_format: A string,\n",
       "        one of `channels_last` (default) or `channels_first`.\n",
       "        The ordering of the dimensions in the inputs.\n",
       "        `channels_last` corresponds to inputs with shape\n",
       "        `(batch, height, width, channels)` while `channels_first`\n",
       "        corresponds to inputs with shape\n",
       "        `(batch, channels, height, width)`.\n",
       "        It defaults to the `image_data_format` value found in your\n",
       "        Keras config file at `~/.keras/keras.json`.\n",
       "        If you never set it, then it will be \"channels_last\".\n",
       "\n",
       "# Input shape\n",
       "    4D tensor with shape:\n",
       "    - If `data_format` is `\"channels_last\"`:\n",
       "        `(batch, rows, cols, channels)`\n",
       "    - If `data_format` is `\"channels_first\"`:\n",
       "        `(batch, channels, rows, cols)`\n",
       "\n",
       "# Output shape\n",
       "    4D tensor with shape:\n",
       "    - If `data_format` is `\"channels_last\"`:\n",
       "        `(batch, upsampled_rows, upsampled_cols, channels)`\n",
       "    - If `data_format` is `\"channels_first\"`:\n",
       "        `(batch, channels, upsampled_rows, upsampled_cols)`\n",
       "\u001b[0;31mFile:\u001b[0m           /media/anthony/USOPP/conda/IA/lib/python3.6/site-packages/keras/layers/convolutional.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "UpSampling2D?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e533160d-090a-439d-ba96-8bbf3b581b64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
