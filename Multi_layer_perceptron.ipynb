{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Deep Learning With Keras</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.models import model_from_json, model_from_yaml, load_model, save_model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Chapter 1</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train/test shape: (60000, 28, 28)\t(10000, 28, 28)\n",
      "Y_train/test shape: (60000,)\t(10000,)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1671)\n",
    "data = np.load(\"/media/anthony/POULOP/DL/mnist.npz\")\n",
    "X_train, X_test = data[\"x_train\"], data[\"x_test\"]\n",
    "Y_train, Y_test = data[\"y_train\"], data[\"y_test\"]\n",
    "print(\"X_train/test shape: {}\\t{}\".format(X_train.shape, X_test.shape))\n",
    "print(\"Y_train/test shape: {}\\t{}\".format(Y_train.shape, Y_test.shape))\n",
    "Y_train, Y_test = np_utils.to_categorical(Y_train, 10), np_utils.to_categorical(Y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshaping the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train/test shape: (60000, 784)\t(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test = X_train.reshape(60000, 784), X_test.reshape(10000, 784)\n",
    "print(\"X_train/test shape: {}\\t{}\".format(X_train.shape, X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rescaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X_train/255, X_test/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1) Simple layer model</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 10)                7850      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=10, input_shape=(784,)))\n",
    "model.add(Activation(\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTIM = RMSprop()\n",
    "model.compile(optimizer=OPTIM, loss=\"categorical_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3227 - accuracy: 0.9104 - val_loss: 0.3086 - val_accuracy: 0.9145\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3218 - accuracy: 0.9106 - val_loss: 0.3078 - val_accuracy: 0.9143\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3210 - accuracy: 0.9107 - val_loss: 0.3072 - val_accuracy: 0.9147\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3201 - accuracy: 0.9112 - val_loss: 0.3066 - val_accuracy: 0.9147\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3192 - accuracy: 0.9112 - val_loss: 0.3059 - val_accuracy: 0.9154\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3185 - accuracy: 0.9117 - val_loss: 0.3053 - val_accuracy: 0.9148\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3177 - accuracy: 0.9115 - val_loss: 0.3046 - val_accuracy: 0.9149\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3169 - accuracy: 0.9120 - val_loss: 0.3040 - val_accuracy: 0.9155\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3162 - accuracy: 0.9121 - val_loss: 0.3036 - val_accuracy: 0.9165\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3155 - accuracy: 0.9122 - val_loss: 0.3029 - val_accuracy: 0.9156\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3148 - accuracy: 0.9129 - val_loss: 0.3024 - val_accuracy: 0.9153\n",
      "Epoch 12/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3141 - accuracy: 0.9127 - val_loss: 0.3018 - val_accuracy: 0.9158\n",
      "Epoch 13/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3134 - accuracy: 0.9130 - val_loss: 0.3013 - val_accuracy: 0.9160\n",
      "Epoch 14/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3128 - accuracy: 0.9133 - val_loss: 0.3008 - val_accuracy: 0.9161\n",
      "Epoch 15/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3121 - accuracy: 0.9133 - val_loss: 0.3004 - val_accuracy: 0.9166\n",
      "Epoch 16/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3115 - accuracy: 0.9134 - val_loss: 0.2999 - val_accuracy: 0.9165\n",
      "Epoch 17/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3109 - accuracy: 0.9133 - val_loss: 0.2994 - val_accuracy: 0.9170\n",
      "Epoch 18/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3103 - accuracy: 0.9143 - val_loss: 0.2989 - val_accuracy: 0.9165\n",
      "Epoch 19/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3097 - accuracy: 0.9141 - val_loss: 0.2984 - val_accuracy: 0.9169\n",
      "Epoch 20/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3092 - accuracy: 0.9140 - val_loss: 0.2980 - val_accuracy: 0.9171\n",
      "Epoch 21/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3086 - accuracy: 0.9144 - val_loss: 0.2976 - val_accuracy: 0.9170\n",
      "Epoch 22/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3080 - accuracy: 0.9147 - val_loss: 0.2972 - val_accuracy: 0.9177\n",
      "Epoch 23/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3075 - accuracy: 0.9149 - val_loss: 0.2969 - val_accuracy: 0.9178\n",
      "Epoch 24/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3070 - accuracy: 0.9147 - val_loss: 0.2964 - val_accuracy: 0.9178\n",
      "Epoch 25/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3065 - accuracy: 0.9151 - val_loss: 0.2960 - val_accuracy: 0.9182\n",
      "Epoch 26/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3060 - accuracy: 0.9152 - val_loss: 0.2956 - val_accuracy: 0.9182\n",
      "Epoch 27/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3055 - accuracy: 0.9156 - val_loss: 0.2953 - val_accuracy: 0.9183\n",
      "Epoch 28/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3049 - accuracy: 0.9153 - val_loss: 0.2949 - val_accuracy: 0.9178\n",
      "Epoch 29/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3045 - accuracy: 0.9155 - val_loss: 0.2946 - val_accuracy: 0.9182\n",
      "Epoch 30/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3041 - accuracy: 0.9154 - val_loss: 0.2943 - val_accuracy: 0.9179\n",
      "Epoch 31/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3036 - accuracy: 0.9159 - val_loss: 0.2939 - val_accuracy: 0.9180\n",
      "Epoch 32/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3032 - accuracy: 0.9159 - val_loss: 0.2936 - val_accuracy: 0.9183\n",
      "Epoch 33/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3027 - accuracy: 0.9159 - val_loss: 0.2932 - val_accuracy: 0.9182\n",
      "Epoch 34/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.3023 - accuracy: 0.9160 - val_loss: 0.2928 - val_accuracy: 0.9180\n",
      "Epoch 35/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3019 - accuracy: 0.9162 - val_loss: 0.2926 - val_accuracy: 0.9187\n",
      "Epoch 36/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3015 - accuracy: 0.9165 - val_loss: 0.2924 - val_accuracy: 0.9185\n",
      "Epoch 37/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3010 - accuracy: 0.9164 - val_loss: 0.2920 - val_accuracy: 0.9187\n",
      "Epoch 38/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3006 - accuracy: 0.9166 - val_loss: 0.2919 - val_accuracy: 0.9190\n",
      "Epoch 39/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3003 - accuracy: 0.9165 - val_loss: 0.2914 - val_accuracy: 0.9189\n",
      "Epoch 40/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2998 - accuracy: 0.9166 - val_loss: 0.2912 - val_accuracy: 0.9192\n",
      "Epoch 41/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2995 - accuracy: 0.9170 - val_loss: 0.2909 - val_accuracy: 0.9195\n",
      "Epoch 42/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2991 - accuracy: 0.9166 - val_loss: 0.2906 - val_accuracy: 0.9194\n",
      "Epoch 43/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2987 - accuracy: 0.9170 - val_loss: 0.2904 - val_accuracy: 0.9192\n",
      "Epoch 44/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2984 - accuracy: 0.9170 - val_loss: 0.2901 - val_accuracy: 0.9197\n",
      "Epoch 45/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2980 - accuracy: 0.9170 - val_loss: 0.2898 - val_accuracy: 0.9197\n",
      "Epoch 46/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2976 - accuracy: 0.9172 - val_loss: 0.2895 - val_accuracy: 0.9197\n",
      "Epoch 47/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2973 - accuracy: 0.9172 - val_loss: 0.2893 - val_accuracy: 0.9197\n",
      "Epoch 48/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2969 - accuracy: 0.9170 - val_loss: 0.2891 - val_accuracy: 0.9197\n",
      "Epoch 49/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.2966 - accuracy: 0.9174 - val_loss: 0.2888 - val_accuracy: 0.9197\n",
      "Epoch 50/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2963 - accuracy: 0.9173 - val_loss: 0.2886 - val_accuracy: 0.9201\n",
      "Epoch 51/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2959 - accuracy: 0.9178 - val_loss: 0.2883 - val_accuracy: 0.9203\n",
      "Epoch 52/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2956 - accuracy: 0.9174 - val_loss: 0.2882 - val_accuracy: 0.9198\n",
      "Epoch 53/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2953 - accuracy: 0.9178 - val_loss: 0.2879 - val_accuracy: 0.9205\n",
      "Epoch 54/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2950 - accuracy: 0.9178 - val_loss: 0.2877 - val_accuracy: 0.9202\n",
      "Epoch 55/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2947 - accuracy: 0.9179 - val_loss: 0.2874 - val_accuracy: 0.9206\n",
      "Epoch 56/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2944 - accuracy: 0.9182 - val_loss: 0.2873 - val_accuracy: 0.9202\n",
      "Epoch 57/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2941 - accuracy: 0.9179 - val_loss: 0.2871 - val_accuracy: 0.9202\n",
      "Epoch 58/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2938 - accuracy: 0.9181 - val_loss: 0.2868 - val_accuracy: 0.9206\n",
      "Epoch 59/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2935 - accuracy: 0.9179 - val_loss: 0.2866 - val_accuracy: 0.9204\n",
      "Epoch 60/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2932 - accuracy: 0.9182 - val_loss: 0.2864 - val_accuracy: 0.9208\n",
      "Epoch 61/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2929 - accuracy: 0.9184 - val_loss: 0.2862 - val_accuracy: 0.9205\n",
      "Epoch 62/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2926 - accuracy: 0.9184 - val_loss: 0.2860 - val_accuracy: 0.9205\n",
      "Epoch 63/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2923 - accuracy: 0.9188 - val_loss: 0.2858 - val_accuracy: 0.9204\n",
      "Epoch 64/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2921 - accuracy: 0.9186 - val_loss: 0.2856 - val_accuracy: 0.9213\n",
      "Epoch 65/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2918 - accuracy: 0.9186 - val_loss: 0.2855 - val_accuracy: 0.9208\n",
      "Epoch 66/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2915 - accuracy: 0.9188 - val_loss: 0.2853 - val_accuracy: 0.9208\n",
      "Epoch 67/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2913 - accuracy: 0.9186 - val_loss: 0.2851 - val_accuracy: 0.9208\n",
      "Epoch 68/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2910 - accuracy: 0.9187 - val_loss: 0.2849 - val_accuracy: 0.9209\n",
      "Epoch 69/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2907 - accuracy: 0.9190 - val_loss: 0.2847 - val_accuracy: 0.9210\n",
      "Epoch 70/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2905 - accuracy: 0.9188 - val_loss: 0.2845 - val_accuracy: 0.9211\n",
      "Epoch 71/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2902 - accuracy: 0.9187 - val_loss: 0.2844 - val_accuracy: 0.9214\n",
      "Epoch 72/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2900 - accuracy: 0.9188 - val_loss: 0.2842 - val_accuracy: 0.9215\n",
      "Epoch 73/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2897 - accuracy: 0.9193 - val_loss: 0.2841 - val_accuracy: 0.9208\n",
      "Epoch 74/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2895 - accuracy: 0.9192 - val_loss: 0.2838 - val_accuracy: 0.9214\n",
      "Epoch 75/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2893 - accuracy: 0.9191 - val_loss: 0.2837 - val_accuracy: 0.9213\n",
      "Epoch 76/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2890 - accuracy: 0.9189 - val_loss: 0.2835 - val_accuracy: 0.9218\n",
      "Epoch 77/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2888 - accuracy: 0.9194 - val_loss: 0.2834 - val_accuracy: 0.9215\n",
      "Epoch 78/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2885 - accuracy: 0.9192 - val_loss: 0.2832 - val_accuracy: 0.9209\n",
      "Epoch 79/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2883 - accuracy: 0.9193 - val_loss: 0.2831 - val_accuracy: 0.9215\n",
      "Epoch 80/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2881 - accuracy: 0.9196 - val_loss: 0.2830 - val_accuracy: 0.9218\n",
      "Epoch 81/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2878 - accuracy: 0.9197 - val_loss: 0.2829 - val_accuracy: 0.9217\n",
      "Epoch 82/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2877 - accuracy: 0.9194 - val_loss: 0.2826 - val_accuracy: 0.9221\n",
      "Epoch 83/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2874 - accuracy: 0.9198 - val_loss: 0.2825 - val_accuracy: 0.9218\n",
      "Epoch 84/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2872 - accuracy: 0.9196 - val_loss: 0.2823 - val_accuracy: 0.9215\n",
      "Epoch 85/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2870 - accuracy: 0.9195 - val_loss: 0.2822 - val_accuracy: 0.9222\n",
      "Epoch 86/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2868 - accuracy: 0.9198 - val_loss: 0.2821 - val_accuracy: 0.9222\n",
      "Epoch 87/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2866 - accuracy: 0.9198 - val_loss: 0.2820 - val_accuracy: 0.9220\n",
      "Epoch 88/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2864 - accuracy: 0.9199 - val_loss: 0.2818 - val_accuracy: 0.9214\n",
      "Epoch 89/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2861 - accuracy: 0.9199 - val_loss: 0.2816 - val_accuracy: 0.9218\n",
      "Epoch 90/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2860 - accuracy: 0.9201 - val_loss: 0.2814 - val_accuracy: 0.9218\n",
      "Epoch 91/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2858 - accuracy: 0.9201 - val_loss: 0.2814 - val_accuracy: 0.9226\n",
      "Epoch 92/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2855 - accuracy: 0.9202 - val_loss: 0.2813 - val_accuracy: 0.9218\n",
      "Epoch 93/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2854 - accuracy: 0.9201 - val_loss: 0.2811 - val_accuracy: 0.9222\n",
      "Epoch 94/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2851 - accuracy: 0.9204 - val_loss: 0.2810 - val_accuracy: 0.9227\n",
      "Epoch 95/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2849 - accuracy: 0.9202 - val_loss: 0.2808 - val_accuracy: 0.9221\n",
      "Epoch 96/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2847 - accuracy: 0.9205 - val_loss: 0.2807 - val_accuracy: 0.9224\n",
      "Epoch 97/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2846 - accuracy: 0.9204 - val_loss: 0.2806 - val_accuracy: 0.9225\n",
      "Epoch 98/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2844 - accuracy: 0.9207 - val_loss: 0.2805 - val_accuracy: 0.9226\n",
      "Epoch 99/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2842 - accuracy: 0.9204 - val_loss: 0.2804 - val_accuracy: 0.9226\n",
      "Epoch 100/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2840 - accuracy: 0.9208 - val_loss: 0.2803 - val_accuracy: 0.9225\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=X_train, y=Y_train, batch_size=128, epochs=100, \n",
    "                    verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2821 - accuracy: 0.9217\n",
      "Loss function: 0.28207147121429443\n",
      "Accuracy: 0.9217000007629395\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x=X_test, y=Y_test, verbose=1)\n",
    "print(\"Loss function: {}\\nAccuracy: {}\".format(score[0], score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2) Multiple layers model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 10)                7850      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               1408      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 27,060\n",
      "Trainable params: 27,060\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Building the model\n",
    "model = Sequential()\n",
    "model.add(Dense(units=10, activation=\"relu\", input_shape=(784, ))) #input layer\n",
    "#model.add(Activation(\"relu\"))\n",
    "model.add(Dense(128, activation=\"relu\")) #first hidden layer\n",
    "#model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.3)) #30% of weight are set to 0\n",
    "model.add(Dense(128, activation=\"relu\")) #second hidden layer\n",
    "#model.add(Activation(\"relu\"))\n",
    "model.add(Dense(10, activation=\"softmax\")) #output layer\n",
    "#model.add(Activation(\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "WARNING:tensorflow:From /home/anthony/miniconda3/envs/DL/lib/python3.7/site-packages/keras/callbacks/tensorboard_v1.py:200: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/anthony/miniconda3/envs/DL/lib/python3.7/site-packages/keras/callbacks/tensorboard_v1.py:203: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "Epoch 1/50\n",
      "48000/48000 [==============================] - 3s 59us/step - loss: 0.0703 - accuracy: 0.9762 - val_loss: 0.1893 - val_accuracy: 0.9566\n",
      "WARNING:tensorflow:From /home/anthony/miniconda3/envs/DL/lib/python3.7/site-packages/keras/callbacks/tensorboard_v1.py:343: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\n",
      "Epoch 2/50\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.0690 - accuracy: 0.9765 - val_loss: 0.1851 - val_accuracy: 0.9576\n",
      "Epoch 3/50\n",
      "48000/48000 [==============================] - 3s 52us/step - loss: 0.0713 - accuracy: 0.9764 - val_loss: 0.1890 - val_accuracy: 0.9579\n",
      "Epoch 4/50\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.0703 - accuracy: 0.9761 - val_loss: 0.1915 - val_accuracy: 0.9583\n",
      "Epoch 5/50\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.0708 - accuracy: 0.9768 - val_loss: 0.1936 - val_accuracy: 0.9570\n",
      "Epoch 6/50\n",
      "48000/48000 [==============================] - 3s 55us/step - loss: 0.0681 - accuracy: 0.9769 - val_loss: 0.1934 - val_accuracy: 0.9574\n",
      "Epoch 7/50\n",
      "48000/48000 [==============================] - 3s 59us/step - loss: 0.0687 - accuracy: 0.9775 - val_loss: 0.1901 - val_accuracy: 0.9578\n",
      "Epoch 8/50\n",
      "48000/48000 [==============================] - 3s 52us/step - loss: 0.0689 - accuracy: 0.9768 - val_loss: 0.1928 - val_accuracy: 0.9574\n",
      "Epoch 9/50\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.0690 - accuracy: 0.9772 - val_loss: 0.1970 - val_accuracy: 0.9557\n",
      "Epoch 10/50\n",
      "48000/48000 [==============================] - 3s 63us/step - loss: 0.0668 - accuracy: 0.9772 - val_loss: 0.1846 - val_accuracy: 0.9592\n",
      "Epoch 11/50\n",
      "48000/48000 [==============================] - 3s 62us/step - loss: 0.0687 - accuracy: 0.9768 - val_loss: 0.1854 - val_accuracy: 0.9582\n",
      "Epoch 12/50\n",
      "48000/48000 [==============================] - 3s 60us/step - loss: 0.0673 - accuracy: 0.9770 - val_loss: 0.1986 - val_accuracy: 0.9584\n",
      "Epoch 13/50\n",
      "48000/48000 [==============================] - 3s 59us/step - loss: 0.0669 - accuracy: 0.9767 - val_loss: 0.1943 - val_accuracy: 0.9580\n",
      "Epoch 14/50\n",
      "48000/48000 [==============================] - 3s 56us/step - loss: 0.0678 - accuracy: 0.9768 - val_loss: 0.1967 - val_accuracy: 0.9572\n",
      "Epoch 15/50\n",
      "48000/48000 [==============================] - 3s 54us/step - loss: 0.0646 - accuracy: 0.9781 - val_loss: 0.2004 - val_accuracy: 0.9571\n",
      "Epoch 16/50\n",
      "48000/48000 [==============================] - 3s 56us/step - loss: 0.0646 - accuracy: 0.9776 - val_loss: 0.2009 - val_accuracy: 0.9566\n",
      "Epoch 17/50\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.0659 - accuracy: 0.9770 - val_loss: 0.1961 - val_accuracy: 0.9561\n",
      "Epoch 18/50\n",
      "48000/48000 [==============================] - 3s 52us/step - loss: 0.0636 - accuracy: 0.9788 - val_loss: 0.2009 - val_accuracy: 0.9566\n",
      "Epoch 19/50\n",
      "48000/48000 [==============================] - 3s 58us/step - loss: 0.0677 - accuracy: 0.9769 - val_loss: 0.1968 - val_accuracy: 0.9566\n",
      "Epoch 20/50\n",
      "48000/48000 [==============================] - 3s 70us/step - loss: 0.0659 - accuracy: 0.9774 - val_loss: 0.1962 - val_accuracy: 0.9571\n",
      "Epoch 00020: early stopping\n"
     ]
    }
   ],
   "source": [
    "#compiling and fitting\n",
    "OPTIM = Adam()\n",
    "my_early_stop = EarlyStopping(monitor='val_loss', patience=10, min_delta=0.0001, verbose=1, mode=\"auto\")\n",
    "my_board = TensorBoard(log_dir='./log', histogram_freq=0, write_graph=True, write_images=False)\n",
    "model.compile(optimizer=OPTIM, loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "history = model.fit(x=X_train, y=Y_train, batch_size=128, epochs=50, \n",
    "                    verbose=1, validation_split=0.2, callbacks=[my_early_stop, my_board])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 48us/step\n",
      "===Testing set===\n",
      "Loss function: 0.15900099079338834\n",
      "Accuracy: 0.954200029373169\n",
      "===Training set===\n",
      "60000/60000 [==============================] - 2s 40us/step\n",
      "Loss function: 0.11188480342915282\n",
      "Accuracy: 0.9642333388328552\n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "score = model.evaluate(x=X_test, y=Y_test, verbose=1)\n",
    "print(\"===Testing set===\")\n",
    "print(\"Loss function: {}\\nAccuracy: {}\".format(score[0], score[1]))\n",
    "\n",
    "print(\"===Training set===\")\n",
    "score = model.evaluate(x=X_train, y=Y_train, verbose=1)\n",
    "print(\"Loss function: {}\\nAccuracy: {}\".format(score[0], score[1]))\n",
    "#SGD optimizer : 0.948 (training set) / 0.947 (testing set)\n",
    "#RMSprop optimize : 0.974 / 0.956\n",
    "#Adam optimizer : 0.983 / 0.956"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "#Predictions\n",
    "test_prediction = model.predict_proba(X_test, batch_size=20)\n",
    "print(test_prediction.shape)\n",
    "train_prediction = model.predict_proba(X_train, batch_size=20)\n",
    "print(train_prediction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, '1-Specificity')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#other visualization method :\n",
    "import sklearn.metrics as metrics\n",
    "fpr, tpr, thresh = metrics.roc_curve(Y_test[:, 7], test_prediction[:, 7])\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "figure = plt.figure(figsize=(13,5))\n",
    "ax1 = figure.add_subplot(1,1,1)\n",
    "ax1.set_title('Roc curve')\n",
    "ax1.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "ax1.legend(loc = 'lower right')\n",
    "ax1.plot([0, 1], [0, 1],'r--')\n",
    "ax1.set_xlim([-0.05, 1])\n",
    "ax1.set_ylim([0, 1.05])\n",
    "ax1.set_ylabel('Sensibility')\n",
    "ax1.set_xlabel('1-Specificity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving\n",
    "##the architecture :\n",
    "json_model = model.to_json()\n",
    "##weights :\n",
    "model.save(\"my_dense_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
